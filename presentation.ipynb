{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18i_1OXzdI1WNnAvhI6py130TTK8J-jk_",
      "authorship_tag": "ABX9TyOYP5aKLyqHpDkBgk9Cnnu+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnapat/CNN_Imageclassified/blob/allone/presentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aaMcLEWYynT",
        "outputId": "86d7ae91-5eb2-4a8d-9a80-8b4cd7dc9f00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "\n",
            "NumPy 1.23.5\n",
            "\n",
            "Matplotlib 3.7.1\n",
            "\n",
            "TensorFlow 2.14.0\n",
            "tf.keras.backend.image_data_format() = channels_last\n",
            "TensorFlow detected 0 GPU(s):\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print( f\"Python {sys.version}\\n\" )\n",
        "\n",
        "import numpy as np\n",
        "print( f\"NumPy {np.__version__}\\n\" )\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print( f\"Matplotlib {matplotlib.__version__}\\n\" )\n",
        "\n",
        "import tensorflow as tf\n",
        "print( f\"TensorFlow {tf.__version__}\" )\n",
        "print( f\"tf.keras.backend.image_data_format() = {tf.keras.backend.image_data_format()}\" )\n",
        "\n",
        "# Count the number of GPUs as detected by tensorflow\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print( f\"TensorFlow detected { len(gpus) } GPU(s):\" )\n",
        "for i, gpu in enumerate(gpus):\n",
        "  print( f\".... GPU No. {i}: Name = {gpu.name} , Type = {gpu.device_type}\" )\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_array(X):\n",
        "  images=[]\n",
        "  for x in X:\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(x).astype(np.uint8)\n",
        "    images.append(img_array)\n",
        "\n",
        "  X_ret = np.array(images)\n",
        "\n",
        "  return X_ret\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def do_augmentation(img,y,aug):\n",
        "\n",
        "  ret_x=[]\n",
        "  ret_y=[]\n",
        "\n",
        "  if aug == 1:\n",
        "    aug_list = [Image.FLIP_LEFT_RIGHT]\n",
        "  elif aug == 2:\n",
        "    aug_list = [Image.ROTATE_180]\n",
        "  elif aug == 3:\n",
        "    #aug_list = [Image.ROTATE_90,Image.ROTATE_180,Image.ROTATE_270]\n",
        "    aug_list = [Image.ROTATE_90,Image.ROTATE_90,Image.ROTATE_90]\n",
        "  elif aug == 4:\n",
        "    #aug_list = [Image.ROTATE_90,Image.ROTATE_180,Image.ROTATE_270,Image.FLIP_LEFT_RIGHT,Image.ROTATE_90,Image.ROTATE_180,Image.ROTATE_270]\n",
        "    aug_list = [Image.ROTATE_90,Image.ROTATE_90,Image.ROTATE_90,Image.FLIP_LEFT_RIGHT,Image.ROTATE_90,Image.ROTATE_90,Image.ROTATE_90]\n",
        "\n",
        "\n",
        "\n",
        "  ret_x.append(img)\n",
        "  ret_y.append(y)\n",
        "\n",
        "  #img = tf.keras.utils.array_to_img(img)\n",
        "\n",
        "  for iaug in aug_list:\n",
        "    img = img.transpose(method=iaug)\n",
        "    #img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    ret_x.append(img)\n",
        "    ret_y.append(y)\n",
        "\n",
        "\n",
        "\n",
        "  return ret_x,ret_y\n",
        "\n",
        "def load_dataset(xlist,ylist,aug=0):\n",
        "\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  cc = 0\n",
        "  for f in xlist:\n",
        "    img = tf.keras.preprocessing.image.load_img(f, target_size=(224, 224))\n",
        "\n",
        "    if aug != 0:\n",
        "      # do aug\n",
        "      img_aug , y_aug = do_augmentation(img=img,y=ylist[cc],aug=aug)\n",
        "\n",
        "      images.extend(img_aug)\n",
        "      labels.extend(y_aug)\n",
        "      #pass\n",
        "\n",
        "    else:\n",
        "      #img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "      img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "      images.append(img)\n",
        "      labels.append(ylist[cc])\n",
        "\n",
        "    cc += 1\n",
        "\n",
        "  return images,labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(path,lables,test_size=0.2, random_state=42,split=True,augmentation=0,do_img_array=0):\n",
        "\n",
        "  x = []\n",
        "  y=[]\n",
        "  x_path=[]\n",
        "  images = []\n",
        "  X_train = np.empty((244,244,3))\n",
        "  X_test = np.array([])\n",
        "  y_train = np.empty( (244,244,3))\n",
        "  y_test =np.array([])\n",
        "\n",
        "  for i in rock_label:\n",
        "    folder_path=f\"{path}/{rock_label[i]}\"\n",
        "    print(folder_path)\n",
        "    files = os.listdir(folder_path)\n",
        "    for file in files:\n",
        "      target_path = f\"{folder_path}/{file}\"\n",
        "      #print(target_path)\n",
        "      #img =  tf.keras.preprocessing.image.load_img(target_path, target_size=(224, 224))\n",
        "      #img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "      #images.append(img)\n",
        "\n",
        "      x_path.append(target_path)\n",
        "      y.append(int(i))\n",
        "\n",
        "  if split == True:\n",
        "    X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(x_path, y, test_size=0.3, random_state=42)\n",
        "    #print(type(X_train_temp))\n",
        "    X_train_temp, y_train_temp = load_dataset(X_train_temp,y_train_temp,augmentation)\n",
        "    #print(type(X_train_temp))\n",
        "    X_test_temp, y_test_temp = load_dataset(X_test_temp,y_test_temp,augmentation)\n",
        "\n",
        "  if split == True:\n",
        "    if do_img_array == 0:\n",
        "      # return with image format\n",
        "      return X_train_temp, X_test_temp, y_train_temp, y_test_temp\n",
        "    else:\n",
        "      # return with nunpy array\n",
        "      X_train_temp = to_array(X_train_temp)\n",
        "      X_test_temp = to_array(X_test_temp)\n",
        "      y_train_temp = np.array(y_train_temp)\n",
        "      y_test_temp = np.array(y_test_temp)\n",
        "\n",
        "      return X_train_temp, X_test_temp, y_train_temp, y_test_temp\n",
        "  else:\n",
        "    return X,Y\n"
      ],
      "metadata": {
        "id": "M4QcZa5yY_N3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"THFOOD50-v1/train\"\n",
        "rock_label={\"0\":\"Joke\",\"1\":\"KaiThoon\",\"2\":\"KaiJeowMooSaap\",\"3\":\"KaoManGai\"}\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = prepare_dataset(path=path,lables=rock_label,split=True,augmentation=3,do_img_array=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oySgCurZBWE",
        "outputId": "01534d03-22ff-4041-b502-e5bdde155fa7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THFOOD50-v1/train/Joke\n",
            "THFOOD50-v1/train/KaiThoon\n",
            "THFOOD50-v1/train/KaiJeowMooSaap\n",
            "THFOOD50-v1/train/KaoManGai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_architecture = {\"VGG16\": VGG16(weights=\"imagenet\", include_top=False),\n",
        "                     \"ResNet50\":ResNet50(weights='imagenet', include_top=False),\n",
        "                     \"MobileNet\":MobileNet(weights='imagenet', include_top=False)}\n",
        "\n",
        "processing= {\"VGG16\": tf.keras.applications.vgg16,\n",
        "                     \"ResNet50\":tf.keras.applications.resnet50,\n",
        "                     \"MobileNet\":tf.keras.applications.mobilenet_v3}\n",
        "\n",
        "base_architecture_list = [\"VGG16\",\"ResNet50\",\"MobileNet\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dxbIkf3a3od",
        "outputId": "14b747a3-b475-4cb0-89dd-fe66cce04723"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_pred=[]\n",
        "for m in base_architecture_list:\n",
        "  print(m)\n",
        "  model = base_architecture[m]\n",
        "  x_train_preprocess = processing[m].preprocess_input(X_train)\n",
        "  x_test_preprocess = processing[m].preprocess_input(X_test)\n",
        "\n",
        "  img_preprocess1 = np.expand_dims(x_train_preprocess[2000],axis=0)\n",
        "  pred = model.predict(img_preprocess1)\n",
        "  list_pred.append(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRGbK5rUgoig",
        "outputId": "fec1d6d2-8cea-4169-8f49-cccbe64ce9c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG16\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "ResNet50\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "MobileNet\n",
            "1/1 [==============================] - 1s 740ms/step\n"
          ]
        }
      ]
    }
  ]
}