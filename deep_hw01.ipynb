{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "12aA6qWKeB-ypqhJjNLPtKW2rvB3qshJp",
      "authorship_tag": "ABX9TyMlIV2S9D3v8LSEjIc21tdr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnapat/CNN_Imageclassified/blob/main/deep_hw01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_65i4mcXsgr",
        "outputId": "0fd03bb9-753b-4e8b-ca2e-3f326894904b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-8f98ebeb-1264-8757-c96e-94705d3e666b)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print( f\"Python {sys.version}\\n\" )\n",
        "\n",
        "import numpy as np\n",
        "print( f\"NumPy {np.__version__}\\n\" )\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print( f\"Matplotlib {matplotlib.__version__}\\n\" )\n",
        "\n",
        "import tensorflow as tf\n",
        "print( f\"TensorFlow {tf.__version__}\" )\n",
        "print( f\"tf.keras.backend.image_data_format() = {tf.keras.backend.image_data_format()}\" )\n",
        "\n",
        "# Count the number of GPUs as detected by tensorflow\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print( f\"TensorFlow detected { len(gpus) } GPU(s):\" )\n",
        "for i, gpu in enumerate(gpus):\n",
        "  print( f\".... GPU No. {i}: Name = {gpu.name} , Type = {gpu.device_type}\" )\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "#from tensorflow.keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxtSB0MpYuxY",
        "outputId": "70ba6b93-89a1-4363-a00b-b7cea55a78b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "\n",
            "NumPy 1.23.5\n",
            "\n",
            "Matplotlib 3.7.1\n",
            "\n",
            "TensorFlow 2.14.0\n",
            "tf.keras.backend.image_data_format() = channels_last\n",
            "TensorFlow detected 0 GPU(s):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def do_augmentation(x,y,aug):\n",
        "\n",
        "  ret_x=[]\n",
        "  ret_y=[]\n",
        "\n",
        "  if aug == 1:\n",
        "    aug_list = [Image.FLIP_LEFT_RIGHT]\n",
        "  elif aug == 2:\n",
        "    aug_list = [Image.ROTATE_180]\n",
        "  elif aug == 3:\n",
        "    #aug_list = [Image.ROTATE_90,Image.ROTATE_180,Image.ROTATE_270]\n",
        "    aug_list = [Image.ROTATE_90,Image.ROTATE_90,Image.ROTATE_90]\n",
        "  elif aug == 4:\n",
        "    #aug_list = [Image.ROTATE_90,Image.ROTATE_180,Image.ROTATE_270,Image.FLIP_LEFT_RIGHT,Image.ROTATE_90,Image.ROTATE_180,Image.ROTATE_270]\n",
        "    aug_list = [Image.ROTATE_90,Image.ROTATE_90,Image.ROTATE_90,Image.FLIP_LEFT_RIGHT,Image.ROTATE_90,Image.ROTATE_90,Image.ROTATE_90]\n",
        "\n",
        "  cc=0\n",
        "  for img in x:\n",
        "    ret_x.append(img)\n",
        "    ret_y.append(y[cc])\n",
        "\n",
        "    img = tf.keras.utils.array_to_img(img)\n",
        "\n",
        "    for iaug in aug_list:\n",
        "      img = img.transpose(method=iaug)\n",
        "      img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "      ret_x.append(img)\n",
        "      ret_y.append(y[cc])\n",
        "\n",
        "    cc += 1\n",
        "\n",
        "  return ret_x,ret_y\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(path,lables,test_size=0.2, random_state=42,split=True,augmentation=0):\n",
        "\n",
        "  x = []\n",
        "  y=[]\n",
        "  images = []\n",
        "  X_train = np.empty((244,244,3))\n",
        "  X_test = np.array([])\n",
        "  y_train = np.empty( (244,244,3))\n",
        "  y_test =np.array([])\n",
        "\n",
        "  for i in rock_label:\n",
        "    folder_path=f\"{path}/{rock_label[i]}\"\n",
        "    #print(folder_path)\n",
        "    files = os.listdir(folder_path)\n",
        "    for file in files:\n",
        "      target_path = f\"{folder_path}/{file}\"\n",
        "      #print(target_path)\n",
        "      img =  tf.keras.preprocessing.image.load_img(target_path, target_size=(224, 224))\n",
        "      img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "      images.append(img)\n",
        "      y.append(int(i))\n",
        "\n",
        "  X = np.array(images)\n",
        "  Y = np.array(y)\n",
        "\n",
        "  if split == True:\n",
        "    X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "    #X_train_temp,y_train_temp = do_augmentation(X_train_temp,y_train_temp,aug=augmentation)\n",
        "  else:\n",
        "    X = np.array(images)\n",
        "    Y = np.array(y)\n",
        "\n",
        "  if split == True:\n",
        "    return X_train_temp, X_test_temp, y_train_temp, y_test_temp\n",
        "  else:\n",
        "    return X,Y"
      ],
      "metadata": {
        "id": "qigRj50NTc4J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"drive/MyDrive/Gz/nida/dl/hw01/Rock\"\n",
        "#rock_label={\"1\":\"Amphibolite\",\"2\":\"Andesite\",\"3\":\"Basalt\",\"4\":\"Carbonatite\",\"4\":\"Coal\"}\n",
        "#rock_label={\"1\":\"Amphibolite\",\"2\":\"Andesite\"}\n",
        "rock_label={\"1\":\"Amphibolite\"}\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = prepare_dataset(path=path,lables=rock_label,split=True,augmentation=3)"
      ],
      "metadata": {
        "id": "0sRjpLHrB2gc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train.shape)\n",
        "X_train"
      ],
      "metadata": {
        "id": "AepKTrw-YETO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow( X_train[1].astype(np.uint8) )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0BMndEoYM8ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_w,img_h = 224,224     # image size of CIFAR-10\n",
        "vgg_extractor = tf.keras.applications.vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_w, img_h, 3))\n",
        "\n",
        "vgg_extractor.summary()"
      ],
      "metadata": {
        "id": "dMUIzEaKZDHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(vgg_extractor, to_file='cnn1_sequential.png', show_shapes=True, show_dtype=True, show_layer_names=False, dpi=96)"
      ],
      "metadata": {
        "id": "Lxr-9iACZDIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess CIFAR-10 dataset to match VGG-16's requirements\n",
        "x_train_vgg = tf.keras.applications.vgg16.preprocess_input(X_train)\n",
        "x_test_vgg = tf.keras.applications.vgg16.preprocess_input(X_test)\n",
        "\n",
        "print( x_train_vgg.dtype, x_train_vgg.shape, np.min(x_train_vgg), np.max(x_train_vgg) )\n",
        "print( x_test_vgg.dtype, x_test_vgg.shape, np.min(x_test_vgg), np.max(x_test_vgg) )"
      ],
      "metadata": {
        "id": "T6VAFj_EcxgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_extractor.trainable = False\n",
        "for i,layer in enumerate(vgg_extractor.layers):\n",
        "    print( f\"Layer {i}: name = {layer.name} , trainable = {layer.trainable}\" )"
      ],
      "metadata": {
        "id": "ATcngHl4c67G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = vgg_extractor.output\n",
        "\n",
        "# Add our custom layer(s) to the end of the existing model\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "new_outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "# Construct the main model\n",
        "model = tf.keras.models.Model(inputs=vgg_extractor.inputs, outputs=new_outputs)"
      ],
      "metadata": {
        "id": "Ay_Ew7oOc-tK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file='vggoutput1.png', show_shapes=True, show_dtype=True, show_layer_names=False, dpi=96)"
      ],
      "metadata": {
        "id": "Va6F8-_-dKfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"] )"
      ],
      "metadata": {
        "id": "JQODTSt0dpAL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit( x_train_vgg, Y_train, batch_size=128, epochs=20, verbose=1, validation_split=0.2 )"
      ],
      "metadata": {
        "id": "VL7aHss6duk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_test_vgg, Y_test, batch_size=128)\n",
        "print( f\"{model.metrics_names}: {results}\" )"
      ],
      "metadata": {
        "id": "uiUnBsF5W2TI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}